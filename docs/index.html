---

title: Reformer Reproducibility Experiments


keywords: fastai
sidebar: home_sidebar

summary: "Fastai community entry to <a href='https://paperswithcode.com/rc2020'>2020 Reproducibility Challenge</a>"
description: "Fastai community entry to <a href='https://paperswithcode.com/rc2020'>2020 Reproducibility Challenge</a>"
nb_path: "nbs/index.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/index.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Project-Links">Project Links<a class="anchor-link" href="#Project-Links"> </a></h3><ul>
<li><a href="https://forums.fast.ai/t/reproducibility-challenge-2020-fastai-folks-interested/80336/39">Fastai forums thread</a></li>
<li><a href="https://docs.google.com/document/d/1wF83E3B3yXIGZixEgOUJI2T2XXhT1DVCrPXS5Dbsyh8/edit">Google doc</a></li>
<li><a href="https://paperswithcode.com/static/rc2020/ML-Reproducibility-Challenge-2020-Template.zip">RC2020 Report Style Template</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Resources">Resources<a class="anchor-link" href="#Resources"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Author's-Code-and-Resources">Author's Code and Resources<a class="anchor-link" href="#Author's-Code-and-Resources"> </a></h3><ul>
<li><a href="https://openreview.net/pdf?id=rkgNKkHtvB">Reformer Paper</a></li>
<li><a href="https://iclr.cc/virtual_2020/poster_rkgNKkHtvB.html">Authors ICLR video</a></li>
<li><a href="https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html">Google Blog</a></li>
<li><a href="https://github.com/google/trax/tree/master/trax/models/reformer">Authors code (TRAX)</a></li>
<li><a href="https://github.com/google/trax/blob/f8024e8057599b92fce82842f342cb3d39c8f405/trax/supervised/configs/reformer_enwik8.gin">Reformer enwik8 model and training config</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="More-Code">More Code<a class="anchor-link" href="#More-Code"> </a></h3><ul>
<li><a href="https://github.com/lucidrains/reformer-pytorch/">@lucidrainâ€™s Reformer code</a></li>
<li><a href="https://github.com/huggingface/transformers/blob/a1bbcf3f6c20e15fe799a8659d6b7bd36fdf11ed/src/transformers/modeling_reformer.py">HuggingFace: Reformer source code</a><ul>
<li><a href="https://github.com/google/trax/blob/master/trax/supervised/configs/reformer_enwik8.gin">Reformer enwik8 configs</a></li>
<li><a href="https://github.com/google/trax/blob/master/trax/supervised/configs/reformer_wmt_ende.gin">Reformer WMT14 en-de configs</a></li>
<li><a href="https://github.com/google/trax/blob/a0483a12cb7ebece40b5e302e8e81fd9249c6ef6/trax/models/reformer/machine_translation.ipynb">Reformer Machine Translation example</a>
= <a href="https://github.com/tensorflow/tensor2tensor/blob/21dba2c1bdcc7ab582a2bfd8c0885c217963bb4f/tensor2tensor/data_generators/text_encoder.py#L448">SubwordTextEncoder tokenizer used for Machine Translation</a></li>
</ul>
</li>
<li><a href="https://colab.research.google.com/github/patrickvonplaten/blog/blob/master/notebooks/03_reformer.ipynb">HuggingFace: Reformer notebook example</a></li>
<li><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/PyTorch_Reformer.ipynb">HuggingFace: long sequences</a></li>
<li><a href="https://colab.research.google.com/drive/1tzzh0i8PgDQGV3SMFUGxM7_gGae3K-uW?usp=sharing">HuggingFace: Pretraining</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Data">Data<a class="anchor-link" href="#Data"> </a></h3><p><strong>enwik8</strong></p>
<ul>
<li><a href="http://mattmahoney.net/dc/enwik8.zip">enwik8.zip, raw data, 100mb</a></li>
<li><a href="https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/enwik8.py">Tensor2Tensor enwik8 data generator code, with train/dev/test split</a>. File lengths:<ul>
<li>Train: 89,621,832</li>
<li>Eval: 5,000,000</li>
<li>Test: 5,000,000</li>
</ul>
</li>
<li><a href="https://github.com/morganmcg1/reformer-fastai/blob/main/enwiki8_Tensor2Tensor_download.ipynb">enwik8 notebook Tensor2Tensor</a></li>
</ul>
<p><strong>WMT14</strong></p>
<ul>
<li><a href="https://huggingface.co/datasets/viewer/?dataset=wmt14&amp;config=cs-en">WMT on HuggingFace Datasets</a></li>
<li><a href="https://github.com/google/trax/tree/a0483a12cb7ebece40b5e302e8e81fd9249c6ef6/trax/models/reformer/testdata">Reformer WMT14 vocab</a></li>
<li>Reformer.input_vocab_size = 33300, from <a href="https://github.com/google/trax/blob/master/trax/supervised/configs/reformer_wmt_ende.gin">WMT14 model config</a></li>
<li>Train Test split: (guess) newstest2013 for validation and newstest2014 for test, in consistence with Vaswani et al. (2017) - from <a href="https://arxiv.org/pdf/2009.02070.pdf">https://arxiv.org/pdf/2009.02070.pdf</a></li>
<li>Tokenizer: <a href="https://github.com/tensorflow/tensor2tensor/blob/21dba2c1bdcc7ab582a2bfd8c0885c217963bb4f/tensor2tensor/data_generators/text_encoder.py#L448">Tensor2Tensor SubWordTextEncoder</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Explainers">Explainers<a class="anchor-link" href="#Explainers"> </a></h3><ul>
<li><a href="https://www.youtube.com/watch?v=i4H0kjxrias&amp;t=1s">Yannic K explainer</a></li>
<li><a href="https://huggingface.co/blog/reformer">HuggingFace blog post</a></li>
<li><a href="https://towardsdatascience.com/illustrating-the-reformer-393575ac6ba0">Illustrating the Reformer blog post</a></li>
<li><a href="https://www.pragmatic.ml/reformer-deep-dive/">Reformer Deep Dive</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Related">Related<a class="anchor-link" href="#Related"> </a></h3><ul>
<li><a href="https://www.coursera.org/learn/attention-models-in-nlp">Coursera Attention Models in NLP course, with Reformer co-author</a></li>
<li><a href="https://hallvagi.github.io/dl-explorer/fastai/attention/lstm/2020/06/29/Attention.html">@hallvagi Attention blogpost</a></li>
<li><a href="https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html">The Transformer Family by @lilianweng</a></li>
<li><a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#a-family-of-attention-mechanisms">A Family of Attention Mechanisms bu @lilianweng</a></li>
</ul>

</div>
</div>
</div>
</div>
 

