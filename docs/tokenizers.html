---

title: Tokenizers


keywords: fastai
sidebar: home_sidebar

summary: "Contains tokenizers used in Reformer paper experiments, converted to fastai transforms"
description: "Contains tokenizers used in Reformer paper experiments, converted to fastai transforms"
nb_path: "nbs/05_tokenizers.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/05_tokenizers.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>No module named &#39;axial_positional_embedding&#39;
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="ByteTextTokenizer">ByteTextTokenizer<a class="anchor-link" href="#ByteTextTokenizer"> </a></h2><p>A tokenizer which encodes each byte in a string to an id. For 8-bit strings only. This is the tokenizer used in Language Modelling tasks in the Reformer paper, based off the implementation in the <a href="https://github.com/tensorflow/tensor2tensor/blob/5f9dd2db6d7797162e53adf152310ed13e9fc711/tensor2tensor/data_generators/text_encoder.py#L176">tensor2tensor library here</a></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ByteTextTokenizer" class="doc_header"><code>class</code> <code>ByteTextTokenizer</code><a href="https://github.com/arampacha/reformer_fastai/tree/master/reformer_fastai/layers.py#L142" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ByteTextTokenizer</code>(<strong><code>is_lm</code></strong>=<em><code>True</code></em>, <strong><code>add_bos</code></strong>=<em><code>False</code></em>, <strong><code>add_eos</code></strong>=<em><code>False</code></em>) :: <code>Transform</code></p>
</blockquote>
<p>Encodes each byte to an id. For 8-bit strings only.
Credit: <a href="https://github.com/tensorflow/tensor2tensor/blob/5f9dd2db6d7797162e53adf152310ed13e9fc711/tensor2tensor/data_generators/text_encoder.py#L176">https://github.com/tensorflow/tensor2tensor/blob/5f9dd2db6d7797162e53adf152310ed13e9fc711/tensor2tensor/data_generators/text_encoder.py#L176</a></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">wonder</span> <span class="o">=</span> <span class="s2">&quot;I wonder how the moon got it&#39;s shine?&quot;</span>
<span class="n">tok</span> <span class="o">=</span> <span class="n">ByteTextTokenizer</span><span class="p">()</span>
<span class="n">tok_wonder</span> <span class="o">=</span> <span class="n">tok</span><span class="p">(</span><span class="n">wonder</span><span class="p">)</span>

<span class="c1"># test string vs list</span>
<span class="k">assert</span> <span class="p">(</span><span class="n">tok</span><span class="p">(</span><span class="n">wonder</span><span class="p">)</span> <span class="o">==</span> <span class="n">tok</span><span class="p">([</span><span class="n">wonder</span><span class="p">]))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">tok</span><span class="p">(</span><span class="n">wonder</span><span class="p">))</span> 
<span class="c1"># assert (tok.decode(tok_wonder) == tok.decode([tok_wonder])).sum() == len(wonder) </span>
<span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">tok_wonder</span><span class="p">)</span> <span class="o">==</span> <span class="n">LMTensorText</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tok_wonder</span><span class="p">)</span> <span class="o">==</span> <span class="mi">37</span>
<span class="k">assert</span> <span class="n">tok</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">tok_wonder</span><span class="p">)</span> <span class="o">==</span> <span class="n">wonder</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tok2</span> <span class="o">=</span> <span class="n">ByteTextTokenizer</span><span class="p">(</span><span class="n">add_bos</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tok_wonder2</span> <span class="o">=</span> <span class="n">tok2</span><span class="p">(</span><span class="n">wonder</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">tok_wonder2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>

<span class="n">tok3</span> <span class="o">=</span> <span class="n">ByteTextTokenizer</span><span class="p">(</span><span class="n">add_eos</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tok_wonder3</span> <span class="o">=</span> <span class="n">tok3</span><span class="p">(</span><span class="n">wonder</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">tok_wonder3</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

