{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 28 01:21:25 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro P5000        On   | 00000000:00:05.0 Off |                  Off |\n",
      "| 26%   27C    P8     6W / 180W |      1MiB / 16278MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install -Uqq fastai einops datasets axial_positional_embedding wandb\n",
    "    !pip install -qq git+git://github.com/arampacha/reformer_fastai.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wikitext-2: n_layers experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *\n",
    "from reformer_fastai.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run setup\n",
    "n_epochs = 10\n",
    "bs = 1\n",
    "sl = 2**15\n",
    "n_layers = 3\n",
    "seed = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have wandb and are logged in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# !wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Experiment Tracking with Weights & Biases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "WANDB_NAME = f'n_layers-{n_layers}_wikitext2_sl-{sl}_bs-{bs}_n_eps-{n_epochs}_seed-{seed}'\n",
    "GROUP = 'n_layers2'\n",
    "NOTES = 'ReformerLM on wikitext2 sl=16k'\n",
    "CONFIG = {}\n",
    "TAGS = ['lm','lsh','wikitext2', 'nlayers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Unpack enwik8 Data\n",
    "\n",
    "Download and unzip wikitext2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "train_ds = load_dataset('wikitext', name='wikitext-2-raw-v1', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitlines(sample):\n",
    "    return {'line':[*sample['text'][0].split('\\n')]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91/cache-b6939be3e780c155.arrow\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.filter(lambda x: x['text'] != '')\n",
    "df = train_ds.data.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btt = ByteTextTokenizer(is_lm=True, add_bos=False, add_eos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.05 s, sys: 121 ms, total: 5.17 s\n",
      "Wall time: 5.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['toks'] = df['text'].apply(btt)\n",
    "df['lens'] = df['toks'].apply(len)\n",
    "df['lens_cum_sum'] = df.lens.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cutoff = 10_000_000\n",
    "train_idxs = df.loc[df['lens_cum_sum'] < train_cutoff].index.values\n",
    "train_idxs = list(range(0, max(train_idxs)))\n",
    "\n",
    "remaining_idxs = len(df) - max(train_idxs)\n",
    "validation_idxs = list(range(max(train_idxs), max(train_idxs) + int(remaining_idxs)))\n",
    "\n",
    "splits = [train_idxs, validation_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [attrgetter(\"text\"), btt]\n",
    "dsets = Datasets(df, [tfms], splits=splits, dl_type=LMDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.16 s, sys: 909 ms, total: 4.07 s\n",
      "Wall time: 4.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dl_kwargs = [{'lens':df['lens'].values[train_idxs]},\n",
    "             {'val_lens':df['lens'].values[validation_idxs]}]\n",
    "dls = dsets.dataloaders(bs=bs, seq_len=sl, dl_kwargs=dl_kwargs, shuffle_train=True, n_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the 1930s , legal restrictions on condoms began to be relaxed . But during this period Fascist Italy and Nazi Germany increased restrictions on condoms ( limited sales as disease preventatives were still allowed ) . During the Depression , condom lines by Schmid gained in popularity . Schmid still used the cement @-@ dipping method of manufacture which had two advantages over the latex variety . Firstly , cement @-@ dipped condoms could be safely used with oil @-@ based lubricants . Secondly , while less comfortable , these older @-@ style rubber condoms could be reused and so were more economical , a valued feature in hard times . More attention was brought to quality issues in the 1930s , and the U.S. Food and Drug Administration began to regulate the quality of condoms sold in the United States . \\n = = Credits and personnel</td>\n",
       "      <td>In the 1930s , legal restrictions on condoms began to be relaxed . But during this period Fascist Italy and Nazi Germany increased restrictions on condoms ( limited sales as disease preventatives were still allowed ) . During the Depression , condom lines by Schmid gained in popularity . Schmid still used the cement @-@ dipping method of manufacture which had two advantages over the latex variety . Firstly , cement @-@ dipped condoms could be safely used with oil @-@ based lubricants . Secondly , while less comfortable , these older @-@ style rubber condoms could be reused and so were more economical , a valued feature in hard times . More attention was brought to quality issues in the 1930s , and the U.S. Food and Drug Administration began to regulate the quality of condoms sold in the United States . \\n = = Credits and personnel =</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse_output\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sz = btt.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb, yb = dls.one_batch()\n",
    "# xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# del xb, yb\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfastai_community\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.15 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">n_layers-3_wikitext2_sl-32768_bs-1_n_eps-10_seed-21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/fastai_community/reformer-fastai\" target=\"_blank\">https://wandb.ai/fastai_community/reformer-fastai</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/fastai_community/reformer-fastai/runs/1zps4tne\" target=\"_blank\">https://wandb.ai/fastai_community/reformer-fastai/runs/1zps4tne</a><br/>\n",
       "                Run data is saved locally in <code>/notebooks/wandb/run-20210128_012139-1zps4tne</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(1zps4tne)</h1><p></p><iframe src=\"https://wandb.ai/fastai_community/reformer-fastai/runs/1zps4tne\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f5a2c81cd30>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_output\n",
    "wandb.init(reinit=True, project=\"reformer-fastai\", entity=\"fastai_community\", \n",
    "           name=WANDB_NAME, group=GROUP, notes=NOTES, tags=TAGS, config=CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReformerLM config \n",
       "--------------------\n",
       "vocab_sz        256\n",
       "d_model         512\n",
       "n_layers        3\n",
       "n_heads         8\n",
       "d_ff            2048\n",
       "ff_chunks       8\n",
       "attn_dropout    0.1\n",
       "ff_dropout      0.1\n",
       "emb_dropout     0.1\n",
       "tie_weights     True\n",
       "causal          True\n",
       "pos_enc         axial\n",
       "max_seq_len     32768\n",
       "axial_shape     None\n",
       "axial_emb_dims  None\n",
       "pad_idx         0\n",
       "prenorm         True\n",
       "attn_bias       False\n",
       "bucket_size     64\n",
       "use_lsh         True\n",
       "n_hashes        8\n",
       "rev_thres       0\n",
       "seed            21"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_id = btt.pad_token_id\n",
    "config = NLayersConfig(d_model=512, d_ff=2048, ff_chunks=8, n_layers=n_layers, max_seq_len=sl, pad_idx=pad_id, seed=seed)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, ReformerLM.from_config(config),\n",
    "                loss_func=CrossEntropyLossFlat(ignore_index=pad_id), opt_func=adafactor,\n",
    "                cbs = [GradientAccumulation(n_acc=8), GradientClip(1.0),\n",
    "                       PadBatchCallback(bucket_size=config.bucket_size,\n",
    "                                        val=pad_id, y_val=pad_id),\n",
    "                       SaveModelCallback(with_opt=True)],\n",
    "                metrics=[accuracy, perplexity, bpc])#.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>bpc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='306' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.63% [5/306 00:36<36:23 11.6874]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(n_epochs, cbs=WandbCallback(log_model=True, log_preds=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
