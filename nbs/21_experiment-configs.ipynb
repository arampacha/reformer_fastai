{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastcore.all import *\n",
    "from fastai.basics import *\n",
    "\n",
    "from reformer_fastai.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConfigBase:\n",
    "    \"Base class for Configs\"\n",
    "    _d:dict = None\n",
    "    _model:Module = None\n",
    "    \n",
    "    def validate(self):\n",
    "        assert exists(self._d), \"_d missing. You might want to provide defaults for config\"\n",
    "        assert exists(self._model), \"_model missing. Provide a model class\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = f\"{self._model.__name__} config \\n\" + '-'*20\n",
    "        s += ''.join(f'\\n{k:16}{v}' for k,v in self._d.items())\n",
    "        return s\n",
    "    \n",
    "    def dict(self): return self._d\n",
    "    \n",
    "    def save(self, fn, add_tstmp=False):\n",
    "        if add_tstmp:\n",
    "            tstmp = time.strftime(\"_%d_%m_%Y_%H:%M\", time.gmtime())\n",
    "            fn += tstmp\n",
    "        save_pickle(fn, self)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file(cls, fn):\n",
    "        return load_pickle(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SyntheticConfig(ConfigBase):\n",
    "    \"\"\"\n",
    "    Config for Synthetic Experiment.\n",
    "    See https://arampacha.github.io/reformer_fastai/experiment.synthetic-task.html for details\n",
    "    \"\"\"\n",
    "    _model = LSHLM\n",
    "    _d = {\n",
    "        'vocab_sz':128,\n",
    "        'd_model':256,\n",
    "        'n_layers':1,\n",
    "        'n_heads':4,\n",
    "        'd_ff':256,\n",
    "        'attn_dropout':0.0,\n",
    "        'ff_dropout':0.0,\n",
    "        'emb_dropout':0.0,\n",
    "        'tie_weights':True,\n",
    "        'causal':True,\n",
    "        'pos_enc':'absolute',\n",
    "        'max_seq_len':1024,\n",
    "        'axial_shape':None,\n",
    "        'axial_emb_dims':None,\n",
    "        'pad_idx':None,\n",
    "        'prenorm':False,\n",
    "        'attn_bias':False,\n",
    "        'bucket_size':64,\n",
    "        'use_lsh':True,\n",
    "        'n_hashes':4,\n",
    "        'random_state':123,\n",
    "    }\n",
    "    \n",
    "    @delegates(_model)\n",
    "    def __init__(self, **kwargs):\n",
    "        self.validate()\n",
    "        for k,v in kwargs.items():\n",
    "            if k in self._d: self._d[k]=v\n",
    "            else: print(f'Parameter {k} is not accepted by LSHLM. Skipped')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSHLM config \n",
       "--------------------\n",
       "vocab_sz        128\n",
       "d_model         256\n",
       "n_layers        1\n",
       "n_heads         4\n",
       "d_ff            256\n",
       "attn_dropout    0.0\n",
       "ff_dropout      0.0\n",
       "emb_dropout     0.0\n",
       "tie_weights     True\n",
       "causal          True\n",
       "pos_enc         absolute\n",
       "max_seq_len     1024\n",
       "axial_shape     None\n",
       "axial_emb_dims  None\n",
       "pad_idx         None\n",
       "prenorm         False\n",
       "attn_bias       False\n",
       "bucket_size     64\n",
       "use_lsh         True\n",
       "n_hashes        4\n",
       "random_state    123"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synt_config = SyntheticConfig()\n",
    "synt_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 02_attention.ipynb.\n",
      "Converted 03_transformer.ipynb.\n",
      "Converted 04_reformer.ipynb.\n",
      "Converted 05_tokenizers.ipynb.\n",
      "Converted 06_data.ipynb.\n",
      "Converted 07_metrics.ipynb.\n",
      "Converted 08_optimizers.ipynb.\n",
      "Converted 09_tracking.ipynb.\n",
      "Converted 10_experiment.synthetic-task.ipynb.\n",
      "Converted 10a_experiment.synthetic-task-comparison.ipynb.\n",
      "Converted 10b_experiment.synthetic-task-minimal.ipynb.\n",
      "Converted 11_experiment.enwik8_baseline.ipynb.\n",
      "Converted 12_experiment.enwik8_sharedQK.ipynb.\n",
      "Converted 13_experiment.enwik8_reversible.ipynb.\n",
      "Converted 20_experiment-script.ipynb.\n",
      "Converted 21_experiment-configs.ipynb.\n",
      "Converted 50_exploration.LSH.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted reproducibility.report_1_reproducibility_summary.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torchenv]",
   "language": "python",
   "name": "conda-env-torchenv-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
