{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> Basic healper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd.profiler as profiler\n",
    "from fastai.basics import *\n",
    "from fastai.text.all import *\n",
    "\n",
    "from functools import partial, reduce, wraps\n",
    "from inspect import isfunction\n",
    "from operator import mul\n",
    "from copy import deepcopy\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "\n",
    "from einops import rearrange, repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General purpose utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d\n",
    "\n",
    "def expand_dim1(x):\n",
    "    if len(x.shape) == 1:\n",
    "        return x[None, :]\n",
    "    else: return x\n",
    "\n",
    "def max_neg_value(tensor):\n",
    "    return -torch.finfo(tensor.dtype).max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# generative helpers\n",
    "# credit https://github.com/huggingface/transformers/blob/a0c62d249303a68f5336e3f9a96ecf9241d7abbe/src/transformers/generation_logits_process.py\n",
    "def top_p_filter(logits, top_p=0.9):\n",
    "    sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "    cum_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "    sorted_indices_to_remove = cum_probs > top_p\n",
    "    sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "    sorted_indices_to_remove[..., 0] = 0\n",
    "    # if min_tokens_to_keep > 1:\n",
    "    #         # Keep at least min_tokens_to_keep (set to min_tokens_to_keep-1 because we add the first one below)\n",
    "    #         sorted_indices_to_remove[..., : min_tokens_to_keep - 1] = 0\n",
    "    indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n",
    "    logits[indices_to_remove] = float('-inf')\n",
    "    return logits\n",
    "\n",
    "def top_k_filter(logits, top_k=20):\n",
    "    indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "    logits[indices_to_remove] = float('-inf')\n",
    "    return logits\n",
    "\n",
    "_sampler = {\n",
    "    'top_k':top_k_filter,\n",
    "    'top_p':top_p_filter,\n",
    "    'gready':lambda x: x.argmax(-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSH specific helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [lucidrains/reformer-pytorch](https://github.com/lucidrains/reformer-pytorch/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def cache_method_decorator(cache_attr, cache_namespace, reexecute = False):\n",
    "    def inner_fn(fn):\n",
    "        @wraps(fn)\n",
    "        def wrapper(self, *args, key_namespace=None, fetch=False, set_cache=True, **kwargs):\n",
    "            namespace_str = str(default(key_namespace, ''))\n",
    "            _cache = getattr(self, cache_attr)\n",
    "            _keyname = f'{cache_namespace}:{namespace_str}'\n",
    "\n",
    "            if fetch:\n",
    "                val = _cache[_keyname]\n",
    "                if reexecute:\n",
    "                    fn(self, *args, **kwargs)\n",
    "            else:\n",
    "                val = fn(self, *args, **kwargs)\n",
    "                if set_cache:\n",
    "                    setattr(self, cache_attr, {**_cache, **{_keyname: val}})\n",
    "            return val\n",
    "        return wrapper\n",
    "    return inner_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def look_one_back(x):\n",
    "    x_extra = torch.cat([x[:, -1:, ...], x[:, :-1, ...]], dim=1)\n",
    "    return torch.cat([x, x_extra], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def chunked_sum(tensor, chunks=1):\n",
    "    *orig_size, last_dim = tensor.shape\n",
    "    tensor = tensor.reshape(-1, last_dim)\n",
    "    summed_tensors = [c.sum(dim=-1) for c in tensor.chunk(chunks, dim=0)]\n",
    "    return torch.cat(summed_tensors, dim=0).reshape(orig_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def sort_key_val(t1, t2, dim=-1):\n",
    "    values, indices = t1.sort(dim=dim)\n",
    "    t2 = t2.expand_as(t1)\n",
    "    return values, t2.gather(dim, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def batched_index_select(values, indices):\n",
    "    last_dim = values.shape[-1]\n",
    "    return values.gather(1, indices[:, :, None].expand(-1, -1, last_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions to assess model performance. Test functions with `mod` and input `x`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = get_text_classifier(AWD_LSTM, vocab_sz=10_000, n_class=10)\n",
    "x = torch.randint(0, 100, (3, 72))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def do_cuda_timing(f, inp, context=None, n_loops=100):\n",
    "    '''\n",
    "        Get timings of cuda modules. Note `self_cpu_time_total` is returned, but\n",
    "        from experiments this appears to be similar/same to the total CUDA time\n",
    "        \n",
    "        f :  function to profile, typically an nn.Module\n",
    "        inp : required input to f\n",
    "        context : optional additional input into f, used for Decoder-style modules\n",
    "    '''\n",
    "    f.cuda()\n",
    "    inp = inp.cuda()\n",
    "    if context is not None: context = context.cuda()\n",
    "    with profiler.profile(record_shapes=False, use_cuda=True) as prof:\n",
    "        with profiler.record_function(\"model_inference\"):\n",
    "            with torch.no_grad():\n",
    "                for _ in range(n_loops):\n",
    "                    if context is None: f(inp)\n",
    "                    else: f(inp, context)\n",
    "                    torch.cuda.synchronize()\n",
    "                    \n",
    "    res = round((prof.key_averages().self_cpu_time_total / 1000) / n_loops, 3)\n",
    "    print(f'{res}ms')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def model_performance(n_loops=5, model='arto', dls=None, n_epochs=1, lr=5e-4):\n",
    "    \"\"\"\n",
    "        DEMO CODE ONLY!\n",
    "        Run training loop to measure timings. Note that the models internally\n",
    "        should be changed depending on the model you would like to use. \n",
    "        You should also adjust the metrics you are monitoring\n",
    "    \"\"\"\n",
    "    acc_ls, ppl_ls =[], []\n",
    "    for i in range(n_loops):\n",
    "        # ADD YOUR MODEL(S) INIT HERE\n",
    "#         if model == 'arto': m = artoTransformerLM(vocab_sz, 512)\n",
    "#         elif model == 'pt': m = ptTransformerLM(vocab_sz, 512)\n",
    "#         else: print('model name not correct')\n",
    "        \n",
    "        learn = Learner(dls, m,\n",
    "                    loss_func=CrossEntropyLossFlat(),\n",
    "                    metrics=[accuracy, Perplexity()]).to_native_fp16()\n",
    "\n",
    "        learn.fit_one_cycle(n_epochs, lr, wd=0.05)\n",
    "        \n",
    "        acc_ls.append(learn.recorder.final_record[2])\n",
    "        ppl_ls.append(learn.recorder.final_record[3])\n",
    "    print(f'Avg Accuracy: {round(sum(acc_ls)/len(acc_ls),3)}, std: {np.std(acc_ls)}')\n",
    "    print(f'Avg Perplexity: {round(sum(ppl_ls)/len(ppl_ls),3)}, std: {np.std(ppl_ls)}')\n",
    "    print()\n",
    "    return learn, acc_ls, ppl_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def total_params(m):\n",
    "    \"\"\"\n",
    "    Give the number of parameters of a module and if it's trainable or not\n",
    "    - Taken from Taken from fastai.callback.hook\n",
    "    \"\"\"\n",
    "    params = sum([p.numel() for p in m.parameters()])\n",
    "    trains = [p.requires_grad for p in m.parameters()]\n",
    "    return params, (False if len(trains)==0 else trains[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of params for our test model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24336280, True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 02_attention.ipynb.\n",
      "Converted 03_transformer.ipynb.\n",
      "Converted 04_reformer.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
