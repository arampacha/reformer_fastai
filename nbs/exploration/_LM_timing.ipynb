{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/arampacha/reformer_fastai/blob/master/nbs/exploration/_LM_timing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan  6 16:07:58 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   71C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for reformer-fastai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for my-timesaver-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install -Uqq fastai einops datasets\n",
    "    !pip install -qq git+git://github.com/arampacha/reformer_fastai.git\n",
    "    !pip install -qq git+git://github.com/butchland/my_timesaver_utils.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reformer_fastai.tokenizers import ByteTextTokenizer\n",
    "from reformer_fastai.transformer import TransformerLM\n",
    "from reformer_fastai.reformer import ReversibleLM\n",
    "from reformer_fastai.metrics import bpc\n",
    "from reformer_fastai.core import total_params\n",
    "from my_timesaver_utils.all import MyProfileCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset tiny_shakespeare (/root/.cache/huggingface/datasets/tiny_shakespeare/default/1.0.0/da11b9a200ca715af415094b34d5c956170f184cb3a58d7789680cf81bede955)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('tiny_shakespeare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitlines(sample):\n",
    "    return {'line':[*sample['text'][0].split('\\n')]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/tiny_shakespeare/default/1.0.0/da11b9a200ca715af415094b34d5c956170f184cb3a58d7789680cf81bede955/cache-442ca6fc9dbbbfc8.arrow\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(splitlines, batched=True, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/tiny_shakespeare/default/1.0.0/da11b9a200ca715af415094b34d5c956170f184cb3a58d7789680cf81bede955/cache-29b7ecbdc2b09017.arrow\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.filter(lambda x: x['line'] != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_ds.data.to_pandas()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bte = ByteTextTokenizer(is_lm=True, add_bos=True, add_eos=True)\n",
    "vocab_sz = bte.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def create_item(self:LMDataLoader, seq):\n",
    "    if seq>=self.n: raise IndexError\n",
    "    sl = self.last_len if seq//self.bs==self.n_batches-1 else self.seq_len\n",
    "    st = (seq%self.bs)*self.bl + (seq//self.bs)*self.seq_len\n",
    "    txt = self.chunks[st : st+sl+1]    \n",
    "    return LMTensorText(txt[:-1]),txt[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = int(len(df)*0.8)\n",
    "splits = range_of(df)[:cut], range_of(df[cut:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [attrgetter(\"line\"), bte]\n",
    "dsets = Datasets(df, [tfms, tfms], splits=splits, dl_type=LMDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,sl = 16,128\n",
    "pad_seq2seq = partial(pad_input, pad_idx=bte.pad_token_id, pad_fields=[0,1])\n",
    "\n",
    "dls = dsets.dataloaders(bs=bs, seq_len=sl, before_batch=pad_seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;bos&gt;O comfortable friar! where is my lord?&lt;eos&gt;&lt;bos&gt;pity: yet I'll tarry till my son come; he hallooed&lt;eos&gt;&lt;bos&gt;Mortal, to cut it off; to cure it,</td>\n",
       "      <td>O comfortable friar! where is my lord?&lt;eos&gt;&lt;bos&gt;pity: yet I'll tarry till my son come; he hallooed&lt;eos&gt;&lt;bos&gt;Mortal, to cut it off; to cure it, e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:&lt;eos&gt;&lt;bos&gt;MONTAGUE:&lt;eos&gt;&lt;bos&gt;My words are dull; O, quicken them with thine!&lt;eos&gt;&lt;bos&gt;And harsh in sound to thine.&lt;eos&gt;&lt;bos&gt;To-night she is mew'd up to her heav</td>\n",
       "      <td>&lt;eos&gt;&lt;bos&gt;MONTAGUE:&lt;eos&gt;&lt;bos&gt;My words are dull; O, quicken them with thine!&lt;eos&gt;&lt;bos&gt;And harsh in sound to thine.&lt;eos&gt;&lt;bos&gt;To-night she is mew'd up to her heavi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransformerLM timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, TransformerLM(vocab_sz, 512),\n",
    "                loss_func=CrossEntropyLossFlat(),\n",
    "                metrics=[accuracy, perplexity, bpc]).to_native_fp16()\n",
    "total_parameters(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>bpc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.350112</td>\n",
       "      <td>3.345185</td>\n",
       "      <td>0.145055</td>\n",
       "      <td>28.365831</td>\n",
       "      <td>4.826082</td>\n",
       "      <td>03:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>bpc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.358690</td>\n",
       "      <td>3.345467</td>\n",
       "      <td>0.145055</td>\n",
       "      <td>28.373833</td>\n",
       "      <td>4.826489</td>\n",
       "      <td>03:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.347866</td>\n",
       "      <td>3.343987</td>\n",
       "      <td>0.145055</td>\n",
       "      <td>28.331861</td>\n",
       "      <td>4.824353</td>\n",
       "      <td>03:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.to_my_profile()\n",
    "learn.fit_one_cycle(2, 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit  called 1 times. max: 465.105 avg: 465.105\n",
      "   epoch  called 2 times. max: 232.679 avg: 232.549\n",
      "      train  called 2 times. max: 209.641 avg: 209.403\n",
      "         train_batch  called 808 times. max: 0.557 avg: 0.413\n",
      "            train_pred  called 808 times. max: 0.179 avg: 0.122\n",
      "            train_loss  called 808 times. max: 0.003 avg: 0.001\n",
      "            train_backward  called 808 times. max: 0.349 avg: 0.261\n",
      "            train_step  called 808 times. max: 0.036 avg: 0.024\n",
      "            train_zero_grad  called 808 times. max: 0.013 avg: 0.005\n",
      "      valid  called 2 times. max: 23.243 avg: 23.136\n",
      "         valid_batch  called 190 times. max: 0.139 avg: 0.135\n",
      "            valid_pred  called 190 times. max: 0.122 avg: 0.118\n",
      "            valid_loss  called 190 times. max: 0.002 avg: 0.001\n"
     ]
    }
   ],
   "source": [
    "learn.my_profile.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.my_profile.clear_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del learn\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReversibleLM timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19298051, True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = Learner(dls, ReversibleLM(vocab_sz, 512),\n",
    "                loss_func=CrossEntropyLossFlat(),\n",
    "                metrics=[accuracy, perplexity, bpc]).to_native_fp16()\n",
    "total_params(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>bpc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.747764</td>\n",
       "      <td>1.668458</td>\n",
       "      <td>0.495296</td>\n",
       "      <td>5.303983</td>\n",
       "      <td>2.407076</td>\n",
       "      <td>03:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>bpc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.224247</td>\n",
       "      <td>2.110697</td>\n",
       "      <td>0.382028</td>\n",
       "      <td>8.253995</td>\n",
       "      <td>3.045093</td>\n",
       "      <td>03:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.914338</td>\n",
       "      <td>1.851212</td>\n",
       "      <td>0.447856</td>\n",
       "      <td>6.367532</td>\n",
       "      <td>2.670734</td>\n",
       "      <td>03:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.to_my_profile()\n",
    "learn.fit_one_cycle(2, 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit  called 2 times. max: 407.500 avg: 305.371\n",
      "   epoch  called 3 times. max: 204.154 avg: 203.576\n",
      "      train  called 3 times. max: 180.776 avg: 180.162\n",
      "         train_batch  called 1212 times. max: 0.465 avg: 0.341\n",
      "            train_pred  called 1212 times. max: 0.182 avg: 0.131\n",
      "            train_loss  called 1212 times. max: 0.004 avg: 0.001\n",
      "            train_backward  called 1212 times. max: 0.236 avg: 0.179\n",
      "            train_step  called 1212 times. max: 0.042 avg: 0.025\n",
      "            train_zero_grad  called 1212 times. max: 0.014 avg: 0.005\n",
      "      valid  called 3 times. max: 23.517 avg: 23.402\n",
      "         valid_batch  called 285 times. max: 0.146 avg: 0.138\n",
      "            valid_pred  called 285 times. max: 0.126 avg: 0.120\n",
      "            valid_loss  called 285 times. max: 0.002 avg: 0.001\n"
     ]
    }
   ],
   "source": [
    "learn.my_profile.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.my_profile.clear_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del learn\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Irreversible blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19298051, True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = Learner(dls, ReversibleLM(vocab_sz, 512, rev_thres=sl+1),\n",
    "                loss_func=CrossEntropyLossFlat(),\n",
    "                metrics=[accuracy, perplexity, bpc]).to_native_fp16()\n",
    "total_params(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>bpc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.258606</td>\n",
       "      <td>2.211136</td>\n",
       "      <td>0.351905</td>\n",
       "      <td>9.126074</td>\n",
       "      <td>3.189994</td>\n",
       "      <td>03:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>bpc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.927476</td>\n",
       "      <td>1.823154</td>\n",
       "      <td>0.455392</td>\n",
       "      <td>6.191355</td>\n",
       "      <td>2.630255</td>\n",
       "      <td>03:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.723771</td>\n",
       "      <td>1.657315</td>\n",
       "      <td>0.497695</td>\n",
       "      <td>5.245211</td>\n",
       "      <td>2.391001</td>\n",
       "      <td>03:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.to_my_profile()\n",
    "learn.fit_one_cycle(2, 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit  called 1 times. max: 466.264 avg: 466.264\n",
      "   epoch  called 2 times. max: 233.288 avg: 233.128\n",
      "      train  called 2 times. max: 210.593 avg: 210.273\n",
      "         train_batch  called 808 times. max: 0.437 avg: 0.420\n",
      "            train_pred  called 808 times. max: 0.128 avg: 0.124\n",
      "            train_loss  called 808 times. max: 0.002 avg: 0.001\n",
      "            train_backward  called 808 times. max: 0.279 avg: 0.266\n",
      "            train_step  called 808 times. max: 0.035 avg: 0.024\n",
      "            train_zero_grad  called 808 times. max: 0.015 avg: 0.005\n",
      "      valid  called 2 times. max: 23.005 avg: 22.846\n",
      "         valid_batch  called 190 times. max: 0.143 avg: 0.138\n",
      "            valid_pred  called 190 times. max: 0.126 avg: 0.120\n",
      "            valid_loss  called 190 times. max: 0.002 avg: 0.001\n"
     ]
    }
   ],
   "source": [
    "learn.my_profile.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.my_profile.clear_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del learn\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
